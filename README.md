# **Challenge Data Analytics Engineer â€“ Mercado Libre**
**SegmentaciÃ³n de Sellers + Clasificador SemÃ¡ntico con GenAI**

Readme generado con IA y validado por revisiÃ³n del autor.
Este repositorio contiene la soluciÃ³n completa del desafÃ­o tÃ©cnico, incluyendo:

- Limpieza y modelado de datos del marketplace
- ConstrucciÃ³n de features a nivel seller
- SegmentaciÃ³n mediante clustering (K-Means)
- EvaluaciÃ³n de calidad de clusters y anÃ¡lisis para negocio
- ExtensiÃ³n GenAI usando embeddings generados por LLM
- Clasificador capaz de asignar sellers nuevos a un cluster
- Pruebas con sellers nunca vistos

## ğŸ“ Estructura del repositorio
```bash
challenge_meli/
â”œâ”€â”€ datos/
â”‚   â”œâ”€â”€ crudo/
â”‚   â”‚   â””â”€â”€ data_por_producto.csv      # Datos iniciales de la prueba
â”‚   â”‚
â”‚   â””â”€â”€ procesado/
â”‚       â”œâ”€â”€ cluster_profile.csv        # Perfil de cada cluster
â”‚       â”œâ”€â”€ data_seller.csv            # Base transformada a nivel seller
â”‚       â””â”€â”€ sellers_clustered.csv      # Sellers limpios + cluster asignado
â”‚
â”œâ”€â”€ modelos/
â”‚   â”œâ”€â”€ embeddings_train.npy           # Embeddings usados en clasificador
â”‚   â”œâ”€â”€ kmeans_sellers_k4.pkl          # Modelo KMeans final
â”‚   â”œâ”€â”€ modelo_logreg_embeddings.pkl   # Clasificador semÃ¡ntico
â”‚   â””â”€â”€ scaler_robust.pkl              # Scaler para clustering
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_exploracion_datos.ipynb
â”‚   â”œâ”€â”€ 02_proc_y_construccion_dataset_sellers.ipynb
â”‚   â”œâ”€â”€ 03_modelado_clusterizacion.ipynb
â”‚   â””â”€â”€ 04_modulo_genai.ipynb
â”‚
â”œâ”€â”€ presentacion/
â”‚   â””â”€â”€ PresentaciÃ³n.pdf               # Deck resumen del challenge
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```


# CÃ³mo ejecutar este proyecto
A continuaciÃ³n se describe el flujo para reproducir completamente el challenge desde cero. Todos los pasos estÃ¡n basados en los notebooks incluidos en este repositorio.

## 0. Requisitos Previos
- Crear un entorno virtual (recomendado)
- Instalar dependencias desde `requirements.txt`
```python
python -m venv .venv
source .venv/Scripts/activate   # En Windows
pip install -r requirements.txt
```
## 1. ExploraciÃ³n Inicial de Datos â€” Notebook 01

- Ubicado en: `notebooks/01_exploracion_datos.ipynb`
- En este notebook se debe cargar la data curda ubicada en `datos/crudo/data_por_producto.csv`

**Contenido y contexto del notebook**

### âœ” RevisiÃ³n estructural del dataset
- 185.250 publicaciones  
- 14 variables originales  
- 46.586 sellers Ãºnicos  

### âœ” DistribuciÃ³n de sellers
- La mayorÃ­a de vendedores tiene muy pocas publicaciones: la mediana es 1 Ã­tem y el 75% tiene â‰¤ 3 productos, mostrando una base amplia de sellers pequeÃ±os/ocasionales.
- La distribuciÃ³n de publicaciones es claramente *long-tail*: existe una cola larga de vendedores con muchas publicaciones, incluyendo outliers por encima de ~1.400 Ã­tems.

### âœ” Precios y Stock
- Las estadÃ­sticas descriptivas de `price` muestran una distribuciÃ³n extremadamente sesgada: la mediana es ~568, mientras que el mÃ¡ximo llega a **4700 millones**, evidenciando outliers econÃ³micos enormes.
- `stock` presenta un patrÃ³n similar: la mediana es 8 unidades, pero existen Ã­tems con **hasta 99.999 unidades**, lo que sugiere la presencia de vendedores mayoristas o catÃ¡logos artificialmente inflados. AdemÃ¡s se detectan productos agotados o sin stock (6k aprox)

### âœ” ReputaciÃ³n del seller
- La mayorÃ­a de vendedores tiene reputaciones positivas: **green (29%)**, **green_silver (14%)**, **green_platinum (13%)** y **green_gold (12%)**. Esto sugiere una base importante de vendedores con trayectoria y buen desempeÃ±o

### âœ” Condition + Refurbished

- El catÃ¡logo estÃ¡ fuertemente dominado por productos **new**, que representan el **91.6%** de todas las publicaciones. Esto sugiere que la mayorÃ­a de los sellers ofrece inventario nuevo, tÃ­pico de vendedores mÃ¡s formales o profesionales.

### âœ” Logistic Type

- La variable `logistic_type` muestra una fuerte predominancia de **XD**, que representa aproximadamente **63%** de las publicaciones. Esto indica que la mayorÃ­a de los productos se gestionan mediante un flujo donde el vendedor entrega al carrier, o deja en un place y la paqueterÃ­a usa un HUB intermedio
- El segundo tipo logÃ­stico mÃ¡s frecuente es **FBM (fulfillment by Mercado Libre)**, con **17%** del catÃ¡logo
 
## 2. ConstrucciÃ³n del Dataset a Nivel Seller â€” Notebook 02

- Ubicado en: `notebooks/02_proc_y_construccion_dataset_sellers.ipynb`
- En este notebook se debe cargar la data curda ubicada en `datos/crudo/data_por_producto.csv`

**Contenido y contexto del notebook**
### âœ” DetecciÃ³n y anÃ¡lisis de nulos
- `regular_price` con **73% nulos** â†’ imputado usando `price`  
- `price` y `stock` con **0** â†’ reglas de negocio para depuraciÃ³n  
- `seller_reputation` con **~1.3% nulos** â†’ eliminados por error de data  

### âœ” Outliers
### MetodologÃ­as probadas:
| MÃ©todo        | Resultado |
|---------------|-----------|
| IQR (1.5Ã— y 3Ã—) | LÃ­mites negativos, mala estabilidad por escala sesgada |
| Percentil 99 (P99) | **Seleccionado**: mejor balance limpieza / preservaciÃ³n |

- EliminaciÃ³n justificada de outliers estructurales.

### âœ” Transformaciones
- `log1p` aplicado a precio y stock â†’ estabiliza escala extremadamente sesgada.
- Todas las decisiones documentadas para modelado posterior.

### âœ” Agregaciones a nivel seller
- NÂº de publicaciones  
- Diversidad de categorÃ­as  
- CategorÃ­a dominante  
- Precio medio / mediano  
- Stock total / medio  
- Flags: `new`, `used`,`not_specified` `refurbished` 
- LogÃ­stica 
- IQR, P99 + log-transforms del notebook anterior  

### âœ” Enriquecimiento
- EntropÃ­a de categorÃ­as â†’ diversificaciÃ³n  
- % de concentraciÃ³n en moda  
- Mapeo ordinal de reputaciÃ³n (0 a 8)  

### âœ” Resultado
Dataset robusto, limpio y listo para clustering:  
â¡ **data_seller.csv**


## 3. Modelado de Clustering â€” Notebook 03
- Ubicado en: `notebooks/03_modelado_clusterizacion.ipynb`

**Contenido y contexto del notebook**

### âœ” PreparaciÃ³n
- Escalamiento robusto (RobustScaler)  
- SelecciÃ³n de features estructurales  

### âœ” SelecciÃ³n de K
Evaluado mediante:
- Elbow Method  
- Silhouette Score  

â†’ Ambos sugieren **K = 4**

### âœ” Entrenamiento
- `KMeans(n_clusters=4, random_state=13, n_init=20)`
- EliminaciÃ³n de outliers residuales en espacio escalado  

### âœ” AnÃ¡lisis de clusters
1. Sellers pequeÃ±os y de baja reputaciÃ³n  
2. Sellers en crecimiento  
3. Sellers diversificados, formales, alta reputaciÃ³n  
4. Sellers especializados y de alta operaciÃ³n logÃ­stica  

â¡ **sellers_clustered.csv**  
â¡ **cluster_profile.csv**


## 4. MÃ³dulo GenAI â€” Clasificador SemÃ¡ntico â€” Notebook 04

- Ubicado en: `notebooks/04_modulo_genai.ipynb`

Este notebook entrena un modelo de clasificaciÃ³n capaz de predecir el cluster de un seller nunca visto, usando embeddings de lenguaje

**Contenido y contexto del notebook**
### âœ” ConstrucciÃ³n del texto descriptivo
"Seller con X publicaciones, Y categorÃ­as, reputaciÃ³n Z, % nuevos..., logÃ­stica..."

### âœ” GeneraciÃ³n de embeddings
- Modelo: **text-embedding-3-small**  
- Batching de 256  
- Se incluyen todas las variables relevantes  

âš  API Key:
```python
os.environ["OPENAI_API_KEY"] = "insertar API key aqui" 
```

# Notas Importantes:

- Ninguna celda depende de parÃ¡metros ocultos o rutas externas. Todo es reproducible
- La API Key **NO** se incluye en el repositorio
- Los modelos ya entrenados estÃ¡n en /modelos por si se desea ejecutar sin entrenar

# Conlusiones Generales:

- Se construyÃ³ un pipeline sÃ³lido desde datos raw â†’ dataset seller â†’ clusters â†’ clasificador.
- El modelo KMeans encontrÃ³ 4 segmentos con interpretabilidad clara y acciÃ³n comercial directa.
- El mÃ³dulo GenAI complementa el proyecto con una soluciÃ³n moderna, escalable y Ãºtil para onboarding.
- Todo el trabajo estÃ¡ documentado en forma de notebooks replicables.
